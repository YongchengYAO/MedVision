![MedVision](fig/medvision-logo.png)

# About

This is the official codebase `medvision_bm` of the **MedVision** project. 

üåè **Project**: [to be updated]

üßëüèª‚Äçüíª **Code**: https://github.com/YongchengYAO/MedVision

ü©ª **Huggingface Dataset**: [https://huggingface.co/datasets/YongchengYAO/MedVision](https://huggingface.co/datasets/YongchengYAO/MedVision)

üê≥ **Docker**: https://hub.docker.com/r/vincentycyao/medvision/tags

<br/>

# üî• News

- [Oct 8, 2025] üöÄ Release **MedVision** dataset v1.0.0

<br/>

# üìú TODO

- [ ] Add preprint and project page
- [x] Release training code 
- [x] Release docker images
- [ ] New tasks guide
- [ ] New models guide

<br/>

# üõ†Ô∏è Install `medvision_bm`

```bash
pip install "git+https://github.com/YongchengYAO/MedVision.git"
```

<br/>

# üê≥ Use Docker

üìù Docker images are built from these [dockerfiles](https://github.com/YongchengYAO/MedVision/tree/master/dockerfile)

1. Choose the docker image for a specific model: https://hub.docker.com/r/vincentycyao/medvision/tags
2. Map local volumes and GPUs

```bash
# NOTE: replace </path/to/local/Data>, </path/to/local/Results>, </path/to/local/SFT> </path/to/completed_tasks>, <tag>
docker run -it --rm \
	--gpus '"device=0,1"' \
	-v </path/to/local/Data>:/root/Documents/MedVision/Data \
	-v </path/to/local/Results>:/root/Documents/MedVision/Results \
	-v </path/to/local/SFT>:/root/Documents/MedVision/SFT \
	-v </path/to/completed_tasks>:/root/Documents/MedVision/completed_tasks \
	vincentycyao/medvision:<tag> \
	bash
```

```bash
# In the container
cd /root/Documents/MedVision
git pull
# Run the scripts in script/
```

[File structure](https://github.com/YongchengYAO/MedVision/tree/master/docs/file-structure.md): imaging data, benchmark results, and model checkpoints are automatically saved

<br/>

# üìä Benchmark

- **[Usage]** 

  1. The scripts in `script/benchmark-*/eval__*` should be sufficient for dependencies installation, data processing, and benchmarking
  2. After evaluating all models in step 1, parse model outputs and calculate metrics (e.g., MRE, MAE, IoU, Success Rate):

  ```bash
  # CLI command: 
  # python -m medvision_bm.benchmark.parse_outputs
  #
  # args:
  # --task_type: ["AD", "TL", "Detection"]
  # --task_dir: task folder
  # --model_dir: model folder
  # --limit: limit sample size in the parsed files
  # --skip_existing: (store_ture arg) skip parsed files
  
  # example 1: parse all models for the T/L task 
  python -m medvision_bm.benchmark.parse_outputs --task_type TL --task_dir Results/MedVision-TL
  
  # example 2: parse one model for the detection task and skip existing parsed files
  python -m medvision_bm.benchmark.parse_outputs --task_type Detection --model_dir Results/MedVision-detect/Qwen2.5-VL-32B-Instruct --skip_existing
  ```

  3. Summarize model performance for each task

  ```bash
  # CLI command: 
  # python -m medvision_bm.benchmark.summarize_AD_task 
  # python -m medvision_bm.benchmark.summarize_detection_task
  # python -m medvision_bm.benchmark.summarize_TL_task
  # python -m medvision_bm.benchmark.analyze_detection_task_boxsize
  # python -m medvision_bm.benchmark.analyze_detection_task_boxsize_vs_random
  #
  # args:
  # --task_dir: task folder
  # --model_dir: model folder
  # --skip_model_wo_parsed_files: skip model directories that don't have a 'parsed' folder
  
  # example 1: summarize all models for the A/D task
  python -m medvision_bm.benchmark.summarize_AD_task --task_dir Results/MedVision-AD
  
  # example 2: summarize one model for the detection task
  python -m medvision_bm.benchmark.summarize_detection_task --model_dir Results/MedVision-detect/Qwen2.5-VL-32B-Instruct
  
  # example 3: analyze how target size affect detection performance
  python -m medvision_bm.benchmark.analyze_detection_task_boxsize --task_dir Results/MedVision-detect
  
  # example 4: compare detection performance with randow guessing
  python -m medvision_bm.benchmark.analyze_detection_task_boxsize_vs_random --task_dir Results/MedVision-detect
  ```

  File structure after these steps:

  ```
  ‚îú‚îÄ‚îÄ MedVision
  	‚îú‚îÄ‚îÄ completed_tasks 
  		‚îú‚îÄ‚îÄ completed_tasks_MedVision-AD.json              # <== tasks status tracker
  		‚îú‚îÄ‚îÄ ...
  	‚îú‚îÄ‚îÄ Results                                            # <== benchmark results
  		‚îú‚îÄ‚îÄ MedVision-AD
  			‚îú‚îÄ‚îÄ ...
  			‚îú‚îÄ‚îÄ summary_AD_task.txt                            # <== !!! summary !!!
  		‚îú‚îÄ‚îÄ MedVision-detect
  			‚îú‚îÄ‚îÄ Qwen2.5-VL-32B-Instruct
  				‚îú‚îÄ‚îÄ parsed                                       # <== folder for parsed files
  					‚îú‚îÄ‚îÄ summary_*.json                             # <== mean metrics in subgroups
  					‚îú‚îÄ‚îÄ *.csv                                      # <== mean metrics in subgroups
  				‚îú‚îÄ‚îÄ *.jsonl                                      # <== model outputs
  				‚îú‚îÄ‚îÄ *.json                                       # <== summary file
  			‚îú‚îÄ‚îÄ ...
  			‚îú‚îÄ‚îÄ summary_detection_task.txt                   # <== !!! summary !!!
  		‚îú‚îÄ‚îÄ MedVision-TL
  			‚îú‚îÄ‚îÄ ...
  			‚îú‚îÄ‚îÄ summary_TL_task.txt                          # <== !!! summary !!!
  ```

- **[Debug]** [here](https://github.com/YongchengYAO/MedVision/tree/master/docs/debug_env_setup.md)


<br/>

# üéØ Training: SFT

- **[Usage]** The scripts in `script/sft-*/train__SFT__*` should be sufficient for dependencies installation, data processing, and training.
- **[Debug]** [here](https://github.com/YongchengYAO/MedVision/tree/master/docs/debug_env_setup.md)

<br/>

# üíø Data Downloading (Optional)

Something about the **MedVision** dataset:

- Concepts
  - `MedVision`: the collection of public imaging data and our annotations
  - `dataset`: name of the public datasets, such `BraTS24`, `MSD`, `OAIZIB-CM`
  - `data-config`: name of predefined subsets
    - naming convention: `{dataset}_{annotation-type}_{task-ID}_{slice}_{split}`
      - `dataset`: [details](https://huggingface.co/datasets/YongchengYAO/MedVision#datasets)
      - `annotation-type`: 
        - `BoxSize`: detection annotations (bounding box)
        - `TumorLesionSize`: tumor/lesion size annotations
        - `BiometricsFromLandmarks`: angle/distance annotations
      - `task-ID`: `Task[xx]`
        - For datasets with multiple image-mask pairs, we defined tasks in `medvision_ds/datasets/*/preprocess_*.py`
        - source: [medvision_ds](https://huggingface.co/datasets/YongchengYAO/MedVision/tree/main/src)
        - e.g., detection tasks for the `BraTS24` dataset is defined in the `benchmark_plan` in `medvision_ds/datasets/BraTS24/preprocess_detection.py`
      - `slice`: [`Sagittal`, `Coronal`, `Axial`]
      - `split`: [`Train`, `Test`]
  
- Any combination of [`data-config` x `split`] will incur the downloading and processing of the whole `dataset`

Since it takes some time for data downloading and processing, you can just download datasets from tasks list (example [here](https://github.com/YongchengYAO/MedVision/tree/master/tasks_list)) or configs list (example [here](https://huggingface.co/datasets/YongchengYAO/MedVision/tree/main/info)) in advance.

‚ö†Ô∏è You need to set API token for these datasets (see [detailed instructions](https://huggingface.co/datasets/YongchengYAO/MedVision#datasets)): FeTA24, SKM-TEA, and ToothFairy2

```bash
# NOTE: replace <task-list-json>
python -m medvision_bm.benchmark.download_datasets --tasks_json <task-list-json>
```
or
```bash
# NOTE: replace <config-list-csv>
python -m medvision_bm.benchmark.download_datasets --configs_csv <config-list-csv>
```

<br/>
